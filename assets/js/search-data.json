{
  
    
        "post0": {
            "title": "Building Successful Ml Products",
            "content": "Building Successful ML Products . In 2019 Gartner predicted 80% of AI projects will remain as experiments run by individuals. This is one of the key reasons why AI/ML Projects fail. Other reasons such as lack of data, talent, platforms, or leadership buy-in are more fundamental in nature, requiring a lot of time and effort to resolve. But once all the hard work is done, failing to operationalize models is undoing all hard work – management might get frustrated and stop sponsoring ML initiatives. .   . Machine learning projects typically start with a problem statement: A specific problem which can be solved using data and analytics. Data is collected and studied, and basic exploratory analysis is done. Data Scientists then run experiments and build models and train them. Upon validation, the model is frozen and outputs are generated. Most projects stop at this stage, and every time there is a need to generate output, the models are run manually .   . There are three major issues with this approach: . Lack of Scalability: Running models manually on local machines will not scale because of limitations in the size of machine. Also, as the scope of the model increases, size of data and steps involved in generating output increases, and hence running the steps manually becomes time consuming and infeasible . | Lack of Process Integration: The end objective of any analytics project is to engrain analytics in business process/applications. Therefore, the whole end-to-end workflow, and integration has to be thought through upfront. The risk of model never being used is higher if workflow and integration become afterthought. . | Model Deterioration: Any analytical model requires maintenance and constant monitoring of output. The quality of predictions deteriorate over a period of time. Model deterioration typically happens because of data drift (Changes in Data pattern over a period of time). . |   . In order to overcome these issues, and increase chances of success, it is recommended to follow a product driven approach to analytics project. The end goal of a product driven approach is to build an Analytic product which is fully integrated with core applications, and something that goes through product lifecycle itself. .   . There are several approaches to build ML products and one such popular approach is the Drivetrain Approach https://www.oreilly.com/radar/drivetrain-approach-data-products/ . Drive train approach is a top-down approach which is driven by business objectives. It seeks to add value to business processes by bringing data and insights into the process flow. Model building is just ‘ another brick in the wall’. Rather than being model centric, this approach strives to be Process and Data centric. Another important aspect of this approach is simulating the end result and the workflow. This is lacking in most of model centric approaches where the entire focus is on algorithms and accuracy metrics of the model. Drive-train approach provides equal weightage to . Business Process improvements . | Application Integration . | Ease of use and consumption . | Models . | MLOps . |   . The following is an extension of Drivetrain approach focusing on Analytical Product Design and Maintenance . Step 1: Clearly define an objective of the Product. Eg: Recommendation engine that can drive sales by surprising and delighting customers. .   . Key Tasks . Understanding Business Challenges and Key Business Processes impacted by the product . | AS-IS process . | Brainstorming ideas with Key Business Stakeholders (why do we need this product? What is the benefit? etc) . | Phrasing Objective Statements and sign off . | .   . Tools (Platform) . MS Word/ Excel/Ppt | .   . Step 2: Simulating the product: Identify workflows, inputs/outputs, interfaces, simulate end result, how will the outputs be consumed? Who are the consumers? How frequently will the product refresh present it to business obtain sign off .   . Key Tasks . Identify Business Processes impacted . | Map process flow and identify Users(Actors), Inputs, Outputs, Processes . | Identify Analytics product touch points with the processes . | Develop Analytics product workflow (Model building inferencing Application integration) . | Define product SLAs - response time etc . | Define inferencing strategy (batch or real-time) . | Define UI/UX where applicable (Eg: process flow which requires users to upload data or trigger a run) . | .   . NOTE: At this point we have still not defined Model or improvements brought by it .   . Tools (Platform) . MS Word/ Excel/Ppt . | Visio . | Jupyter notebook . | . Step 3: Identify levers of the product - What is the USP of the product? Eg: Ranking of recommendations, Sharp recommendations - at fit and size level with CTA and images of the product. . Key Tasks . Define “Improvements” to be brought to the process very clearly. What constitutes significant improvement to existing process? What are the levers that can be used? . | What is the USP of this product? . | .   . Tools (Platform) . MS Word/ Excel/Ppt | . Step 4: Gather relevant data needed to bring the improvements . Define what data are needed . | Identify Data Sources and Gather them (if data is not available see if they can be sourced afresh) . | Data Preparation . | EDA . | Insights . | Freeze all Data requirements, and Preparation . | .   . Tools /Platform . MS Word/ Excel/Ppt . | SQL Workbench . | Jupyter notebook (Local machine / Azure ML) . | Azure ML . | .   . Step 5 Modelling - Select relevant models, experiment with multiple models . Select candidate models . | Simulate input and outputs of the model . | Prepare data for inputting into the model . | Start Experimentation . Feature extraction . | Feature engineering . | Model building . | Model testing and validation . | Model selection . | . | .  Tools /Platform . SQL Workbench . | Jupyter notebook (Local machine / Azure ML) . | Azure ML . | .   . Step 6: MLOps . Deploy Pipelines to production . | Create Inferencing end points and share them with consuming applications . | Testing . | Schedule model run frequency . | Deploy model quality monitor and alerting mechanism . | Access control . | . Tools /Platform . Azure ML | .   . Step 7: Complete Product Development and Rollout . Build UI of the product (Eg: interface for uploading data, or triggering a model run) . | Build Dashboards . | Deploy Solutions and roll out product . | .   .  Tools /Platform . Azure ML . | App development platform (for UI/UX , if required) . | Jupyter notebook . | .",
            "url": "https://srinivasg2306.github.io/blog/2021/05/03/Building-Successful-ML-Products.html",
            "relUrl": "/2021/05/03/Building-Successful-ML-Products.html",
            "date": " • May 3, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Analytics Course Done Now What",
            "content": "I completed Analytics and Business Intelligence program at IIMB in 2019. This is a one-year program which is pretty involved. It starts with fundamentals of Statistics, and covers advanced topics including Deep learning and Reinforcement learning. The program is pretty comprehensive and well thought out and is useful for people who want to move into Analytics field, or would like to advance their career in Analytics. . The course is focussed on concepts rather than tools or Operationalization of Analytics. It does not cover Cloud Platforms either. For more information about the course visit https://iimb.ac.in/eep/product/259/Business-Analytics-Intelligence .   . Coming from Data background, my primary objective of taking the course was to get myself familiarized with Data Science, ML and DL, and get some hands-on experience in Python, R and other popular tools in advanced analytics. . Of course, I did realize that the course would not equip me with everything that is required to jump start an analytics career. However, it was a good place to start with, and given my experience in Data Engineering, the course was a nice complement to my existing skill set. The course helped me switch job and move into Head of Analytics role, which was one of my key objectives, and it was fulfilling to have found a new job while still doing the course .   . 6 months into my new job, I realized that real-life challenges are not really about Data Science, Algorithms or selection of models. I noted that i could not simply put my knowledge and skillsets gained during the period of the Course to use. . My first challenge was to get Data. Sourcing, Profiling, Curating, Storing and then Governing data was my first challenge. This took nearly an year to sort out. Organizations go through Analytics journey in phases. First phase is the Data Phase - Consolidating Organizational level data into a central repository, Second Phase is BI: Doing basic descriptive Analytics, and Business intelligence to help in decision making, and monitoring KPIs. Third phase: Advanced Analytics: Predictive Analytics, Prescriptive Analytics and Final Phase where Data, BI and Advanced Analytics are seamlessly integrated and a stable platform is established, and robust delivery processes such as MLOps are established. .   . I found myself at the beginning of Phase 1 of the journey, but my course was relevant to Phase 3 or 4. The challenge was how to leverage my skill sets in the present scenario? I suppose many of my batch mates found themselves in similar situations. And in general a large number of organizations are in early stages of their analytics journey where the focus tends to be on Data and BI. And fair enough because these are low hanging fruits, and provide highest value to the organizations. .   . So, what now? I had two options - just focus on Data and BI only, and take up advanced analytics at a later time when both Data and BI are in stable state, and advanced. This would mean that there will be no advanced analytics project for next 2 - 3 years. The other option is to take baby-steps in advanced analytics while accelerating data and BI improvements. This will then take couple of years by which time Advanced Analytics practiced would have matured to a certain level. So, I hired a Data Scientist and set up a basic windows server with R, and Python installed in it. Data Scientists were now able to analyse data, and build basic models. .   . In my next blog, i will talk about how did things go? What went right and what went wrong? What are some of the things we should have done upfront before setting up Analytics practice etc. .",
            "url": "https://srinivasg2306.github.io/blog/2021/05/02/Analytics-Course-Done-Now-What.html",
            "relUrl": "/2021/05/02/Analytics-Course-Done-Now-What.html",
            "date": " • May 2, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "About P Values And Hypothesis Testing",
            "content": "There are two contrasting views of Hypothesis testing. There is a group which is of the view that Hypothesis testing is essential for establishing statistical significance of a metric, is an essential part of Model validation. There is another group which believes that Hypothesis does not really prove or disprove a theory, but merely measures data sufficiency to arrive at any conclusion. For now, let us assume that Hypothesis testing is useful, and narrate an example . Marketing Campaigns are done in the form of sending messages from a company to its customers with an objective of increasing sales. It is believed that when messages are sent, some of the customers see them. Few among them will be driven to make a purchase, typically, over a period of time. Messages are sent to customers, and their purchases are tracked for a period of time. Any sale happening during the period is attributed to the messages sent during that period. . (it is assumed that there is only one marketing message during the period, if there are multiple messages then the sale is attributed either to the first or last message) .   . The attribution process is not fool-proof, and is driven by a lot of theory than actual facts. It is hard to believe that an SMS can drive crores of sales (RoI is absurdly high in these cases). In reality, the reasons can be different - Offers, Events like Birthday wedding etc., or any unknown needs of customers. While it is difficult to predict why a customer buys, it is possible to trigger a need for purchase in a customer by sending a communication at right time. .   . Nevertheless, it is important to have a strong measure for lift and attribution in order to establish whether a marketing campaign works or not. One way of measuring effectiveness of campaign is by creating test and control groups. So how do we create test and control groups? To understand this, we need to know the meaning of “Strength of Test”. The article below gives good information - . https://www.markhw.com/blog/control-size . The strength of test is highest when sample sizes are equally split among test and control, and rapidly diminishes when control group goes below 20%. Depending on the total size of the sample set, any number between 50-20% would be ideal. .   . How to measure statistical significance of lift? . We run 2 sample Z test for proportion to check Significance . H0: Response rate of Test Group = Response rate of Control Group (There is no significance difference in response rates between Test and Control Groups) . Ha : Response rate of Test Group is not equal to Response rate of Control Group .   .   . Z = (P1-P2)/(sqrt(P(1-P)*(1/N1 + 1/N2)) . P1= response proportion in test group . P2 = response proportion in control group . N1 = size of test group . N2 = size of control group . P = (N1*P1 + N2*P2)/(N1+N2) .   . The value of Z for two tailed test at 95% significance level is 1.96. That is - there is a 95% chance that you will retain null hypothesis when it is true, if your Z statistic is 1.96 or more. . P value - chances of observing the test statistic value given that the null hypothesis is true. P value should be as low as possible for us to be confidently reject null hypothesis. It should definitely be &lt; 0.05 base minimum for us to reject null hypothesis .   . You can run an experiment keeping P1, P2 constant but increasing N1 and N2. You will see that the Z value increases even if you increase the numbers in the original proportion of N1 and N2. This clearly indicates that as the size of data grows even if the proportion of test and control group remains same, the significance increases. . Similarly, you can keep N1 and N2 constant and vary values of P1 and P2 such that P1-P2 increases, in this case, as P1-P2 increases, the significance value increases . In conclusion, Hypothesis tests can be used to check sufficiency of data to make any conclusion about the Hypothesis. It never provides a conclusive evidence supporting a Hypothesis. Nevertheless, it helps in determining if observations are entirely random or due to interaction between certain variables. .",
            "url": "https://srinivasg2306.github.io/blog/2021/05/02/About-p-values-and-Hypothesis-Testing.html",
            "relUrl": "/2021/05/02/About-p-values-and-Hypothesis-Testing.html",
            "date": " • May 2, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am a Data and Analytics Enthusiast. Although most part of my career was spent building Mainframe Applications, I discovered that my passion was really in Math, Stats, Data and Analytics. I just love progaming in Python, and try to stay in touch with latest in the field. I consider myself a student and blogging is one of the best way to learn and review concepts. So here I am!! . Here is my Linkedin Profile . https://www.linkedin.com/in/srinivas-gopinath-7948593a/ .",
          "url": "https://srinivasg2306.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://srinivasg2306.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}